# -*- coding: utf-8 -*-
"""nasa.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IfW4uzEBxAjZefa68YMnN2NEd_KOt9JN
"""

from __future__ import absolute_import, division, print_function, unicode_literals
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import IPython.display as display
import PIL.Image
import time
import tensorflow_probability as tfp
import functools
from scipy.optimize import fmin_l_bfgs_b
import scipy.optimize as sopt
#import ipdb

#def _make_val_and_grad_fn(value_fn):
#    @functools.wraps(value_fn)
#    def val_and_grad(x):
#        return tfp.math.value_and_gradient(value_fn, x)
#    return val_and_grad

#Function to load an image from a path and reshape it to a given max dim
def load_img(path_to_img, max_dim):
    img = tf.io.read_file(path_to_img)
    img = tf.image.decode_image(img)
    img = tf.image.convert_image_dtype(image=img,dtype=tf.float32)
    aspekt = img.shape[0]/img.shape[1]
    if aspekt>1:
        new_height = max_dim
        new_width = tf.cast(max_dim/aspekt,tf.int32)
    else:
        new_height = tf.cast(max_dim*aspekt,tf.int32)
        new_width = max_dim
    img = tf.image.resize(img,(new_height,new_width))
    img = tf.expand_dims(img,0)
    return img

path_content = '/content/drive/My Drive/FPDS/Weihnachtsmarkt.jpg'
path_style = '/content/drive/My Drive/FPDS/space.jpg'

max_dim = 256
content_image = load_img(path_content,max_dim)
style_image = load_img(path_style,max_dim)
image_shape = content_image.numpy().shape

content_layers = ["block5_conv2"]
num_content_layers = len(content_layers)
style_layers = ["block1_conv1","block2_conv1","block3_conv1","block4_conv1","block5_conv1"]
num_style_layers = len(style_layers)

#Function to create a model using Keras functional API
def vgg_layers(layer_names):
    vgg19 = tf.keras.applications.VGG19(include_top=False,weights="imagenet")
    model = tf.keras.models.Model(inputs=vgg19.input,outputs=[vgg19.get_layer(layer).output for layer in layer_names])
    return model

#Function to compute the Gramm matrix
def gram_matrix(input_tensor):
    gram = tf.linalg.einsum('aijb,aijc->abc',input_tensor,input_tensor)
    shape = tf.shape(input_tensor)
    produkt = tf.cast(shape[1]*shape[2],tf.float32)
    return gram/produkt

#Keras Subclassing API
class StyleContentModel(tf.keras.models.Model):
    
    def __init__(self, style_layers, content_layers):
        super(StyleContentModel, self).__init__()
        self.vgg =  vgg_layers(style_layers + content_layers)
        self.style_layers = style_layers
        self.content_layers = content_layers
        self.num_style_layers = len(style_layers)
        self.vgg.trainable = False
        
    def call(self, inputs):
        inputs = inputs*255.0
        preprocessed_input = tf.keras.applications.vgg19.preprocess_input(inputs)
        outputs = self.vgg(preprocessed_input)
        content_outputs, style_outputs = (outputs[self.num_style_layers:],outputs[:self.num_style_layers])
        
        style_outputs = [gram_matrix(element) for element in style_outputs]
        
        content_dict = {content_name:value for content_name, value in zip(self.content_layers, content_outputs)}
        style_dict = {style_name:value for style_name, value in zip(self.style_layers, style_outputs)}
        return {'content':content_dict, 'style':style_dict}

extractor = StyleContentModel(style_layers=style_layers,content_layers=content_layers)

style_targets = extractor(style_image)['style'] #Extracting the style targets
content_targets = extractor(content_image)['content'] #Extracting the content targets

#Initialising an image to start with
start_image = tf.Variable(content_image)

#Values of alpha and beta from loss function
content_weight = 1.0
style_weight = 100.0

#Optimizer
opt = tf.optimizers.Adam(learning_rate=0.02,beta_1=0.99,epsilon=1e-1)

#Function to clip value
def clip_0_1(image):
    return tf.clip_by_value(image,clip_value_min=0.0,clip_value_max=1.0)

#Defining loss function
def style_content_loss(outputs, style_targets, content_targets, style_weight, content_weight,
                       num_style_layers, num_content_layers):
    style_outputs = outputs['style']
    content_outputs = outputs['content']
    style_loss = tf.add_n([tf.reduce_sum((style_outputs[name]-style_targets[name])**2 / (tf.cast((2*tf.shape(style_outputs[name])[-1])**2, tf.float32))) for name in style_outputs.keys()])
    style_loss *= style_weight / num_style_layers
    content_loss = tf.add_n([tf.reduce_sum(0.5*(content_outputs[name]-content_targets[name])**2) for name in content_outputs.keys()])
    content_loss *= content_weight / num_content_layers
    loss = style_loss + content_loss
    return loss

#Tensor to image
def tensor_to_image(tensor):
    tensor = tensor * 255
    tensor = np.array(tensor, dtype=np.uint8)
    if np.ndim(tensor) > 3:
        assert tensor.shape[0] == 1
        tensor = tensor[0]
    return PIL.Image.fromarray(tensor)

#Total variational weight
total_variation_weight = 100

#Defining one step of training

def train_step(extractor, image, style_targets, content_targets, style_weight, content_weight,
               num_style_layers, num_content_layers, opt,total_variation_weight):
    with tf.GradientTape() as tape:
        outputs = extractor(image)
        loss = style_content_loss(outputs, style_targets, content_targets, style_weight, content_weight,
                       num_style_layers, num_content_layers) + total_variation_weight*tf.image.total_variation(image)
        
    
    grad = tape.gradient(loss,image)
    opt.apply_gradients([(grad, image)])
    image.assign(clip_0_1(image))
    return loss

#@_make_val_and_grad_fn
def loss(image):
    outputs = extractor(image)
    loss_value = style_content_loss(outputs, style_targets, content_targets, style_weight, content_weight,
                       num_style_layers, num_content_layers) + total_variation_weight*tf.image.total_variation(image)
    return loss_value

# print(content_targets['block5_conv2'].shape)
# image_shape
# plt.matshow(content_targets['block5_conv2'][0,:,:,-1])

#results = tfp.optimizer.bfgs_minimize(loss,initial_position=start_image,tolerance=1e-8,max_iterations=1)
#final_image = results.position
#file_name = '/content/drive/My Drive/FPDS/Weihnachts_stilisiert_space_lbfgs.jpg'
#tensor_to_image(final_image).save(file_name)

image_shape

def val_and_grad(img):
  img = tf.convert_to_tensor(np.reshape(img,image_shape),dtype=tf.float32)
  with tf.GradientTape() as tape:
    tape.watch(img)
    loss_val = loss(image=img)
  grad = tape.gradient(loss_val,img)
  return loss_val, grad

def f(x):
  # ipdb.set_trace()
  return [vv.numpy().flatten().astype(np.float64) for vv in val_and_grad(x)]

epochs = 1000
final_image = start_image
for i in range(epochs):
  results = sopt.minimize(fun=f,x0=final_image.numpy().flatten(),jac=True,method='L-BFGS-B',tol=1e-6,options={'maxiter':1})
  # ipdb.set_trace()
  final_image = tf.convert_to_tensor(np.reshape(results.x,start_image.numpy().shape),dtype=tf.float32)
  if i%1000==0:
    file_name = '/content/drive/My Drive/FPDS/Weihnachts_stilisiert_space_lbfgs_{}.jpg'.format(i)
    tensor_to_image(final_image).save(file_name)